---
title: FC100
layout: leaderboard
---


## Fewshot-CIFAR100 Leaderboard (5-class)

#### [Edit this leaderboard](https://github.com/yaoyao-liu/few-shot-classification-leaderboard/edit/main/fc100.md)

Method   | Venue | Year | Backbone   | Setting | 1-shot      | 5-shot   | Code | Reported by 
------- | ------ | ---- | --------   | -----     | -----   | -----    | ---- | ----
[FewTURE](https://arxiv.org/pdf/2206.07267.pdf) | NeurIPS | 2022 | Swin-Tiny | Inductive | 47.68 ± 0.78 |  63.81 ± 0.75 | [\[PyTorch\]](https://github.com/mrkshllr/FewTURE) | [\[Source\]](https://arxiv.org/pdf/2206.07267.pdf)
[FewTURE](https://arxiv.org/pdf/2206.07267.pdf) | NeurIPS | 2022 | ViT-Small | Inductive | 46.20 ± 0.79 |  63.14 ± 0.73 | [\[PyTorch\]](https://github.com/mrkshllr/FewTURE) | [\[Source\]](https://arxiv.org/pdf/2206.07267.pdf)
[HCTransformers](https://arxiv.org/pdf/2203.09064v1.pdf) | CVPR | 2022 | ViT-S | Inductive | 48.27 ± 0.15 | 66.42 ± 0.16 | [\[PyTorch\]](https://github.com/StomachCold/HCTransformers) | [\[Source\]](https://arxiv.org/pdf/2203.09064v1.pdf)
[EASY](https://arxiv.org/pdf/2201.09699.pdf) | arXiv |  2022 | 2xResNet-12(1/√2) | Transductive |   54.47 ± 0.24 |   65.82 ± 0.19 |  [\[PyTorch\]](https://github.com/ybendou/easy) |  [\[Source\]](https://arxiv.org/pdf/2201.09699.pdf)
[EASY](https://arxiv.org/pdf/2201.09699.pdf) | arXiv |  2022 | 3xResNet-12 | Transductive |  54.13 ± 0.24 |    66.86 ± 0.19 |  [\[PyTorch\]](https://github.com/ybendou/easy) |  [\[Source\]](https://arxiv.org/pdf/2201.09699.pdf)
[EASY](https://arxiv.org/pdf/2201.09699.pdf) | arXiv |  2022 | 2xResNet-12(1/√2) | Inductive |   47.94 ± 0.19 |   64.14 ± 0.19 |  [\[PyTorch\]](https://github.com/ybendou/easy) |  [\[Source\]](https://arxiv.org/pdf/2201.09699.pdf)
[EASY](https://arxiv.org/pdf/2201.09699.pdf) | arXiv |  2022 | 3xResNet-12 | Inductive |  48.07 ± 0.19 |  64.74 ± 0.19 |  [\[PyTorch\]](https://github.com/ybendou/easy) |  [\[Source\]](https://arxiv.org/pdf/2201.09699.pdf)
[MetaOptNet](https://arxiv.org/pdf/1904.03758.pdf)     | CVPR   | 2019 | ResNet-12  | Inductive |  41.1 ± 0.6    | 55.5 ± 0.6     | [\[PyTorch\]](https://github.com/kjunelee/MetaOptNet) | [\[Source\]](https://arxiv.org/pdf/1904.03758.pdf)
[MTL](https://openaccess.thecvf.com/content_CVPR_2019/papers/Sun_Meta-Transfer_Learning_for_Few-Shot_Learning_CVPR_2019_paper.pdf)     | CVPR   | 2019 | ResNet-12  | Inductive | 45.1 ± 1.8    | 57.6 ± 0.9    |  [\[PyTorch\]](https://github.com/yaoyao-liu/meta-transfer-learning/) | [\[Source\]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Sun_Meta-Transfer_Learning_for_Few-Shot_Learning_CVPR_2019_paper.pdf)
[MAML](https://arxiv.org/pdf/1703.03400.pdf) | ICML | 2017 | 4CONV | Inductive |  38.1 ± 1.7 | 50.4 ± 1.0   | [\[TensorFlow\]](https://github.com/cbfinn/maml) | [\[Source\]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Sun_Meta-Transfer_Learning_for_Few-Shot_Learning_CVPR_2019_paper.pdf)
[TADAM](http://papers.nips.cc/paper/7352-tadam-task-dependent-adaptive-metric-for-improved-few-shot-learning.pdf)     | NeurIPS   | 2018 | ResNet-12  | Inductive | 40.1 ± 0.4    |  56.1 ± 0.4     | [\[TensorFlow\]](https://github.com/ElementAI/TADAM) | [\[Source\]](http://papers.nips.cc/paper/7352-tadam-task-dependent-adaptive-metric-for-improved-few-shot-learning.pdf)
[DeepEMD](https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_DeepEMD_Few-Shot_Image_Classification_With_Differentiable_Earth_Movers_Distance_and_CVPR_2020_paper.pdf) | CVPR | 2020 | ResNet-12 | Inductive |  46.47 ± 0.78 | 63.22 ± 0.71  | [\[PyTorch\]](https://github.com/icoz69/DeepEMD) | [\[Source\]](https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_DeepEMD_Few-Shot_Image_Classification_With_Differentiable_Earth_Movers_Distance_and_CVPR_2020_paper.pdf)
[ProtoNets](https://arxiv.org/pdf/1703.05175.pdf) | NeurIPS | 2017 | ResNet-12 | Inductive | 41.54 ± 0.76  | 57.08 ± 0.76 | [\[PyTorch\]](https://github.com/orobix/Prototypical-Networks-for-Few-shot-Learning-PyTorch) | [\[Source\]](https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_DeepEMD_Few-Shot_Image_Classification_With_Differentiable_Earth_Movers_Distance_and_CVPR_2020_paper.pdf)
[Dhillon et al.](https://openreview.net/pdf?id=rylXBkrYDS) | ICLR | 2020 | WRN-28-10 | Transductive |  43.16 ± 0.59 | 57.57 ± 0.55 | None | [\[Source\]](https://openreview.net/pdf?id=rylXBkrYDS)
[SIB](https://openreview.net/pdf?id=Hkg-xgrYvH) | ICLR | 2020 | WRN-28-10 | Transductive |  45.2 | 55.9 | [\[PyTorch\]](https://github.com/hushell/sib_meta_learn) | [\[Source\]](https://openreview.net/pdf?id=Hkg-xgrYvH)
[DeepEMD v2](https://arxiv.org/pdf/2003.06777.pdf) | TPAMI | 2022 | ResNet-12 | Inductive |  46.60 ± 0.26 | 63.22 ± 0.71  | [\[PyTorch\]](https://github.com/icoz69/DeepEMD) | [\[Source\]](https://arxiv.org/pdf/2003.06777.pdf)
[E<sup>3</sup>BM](https://arxiv.org/pdf/1904.08479.pdf) | ECCV | 2020 | ResNet-12 | Inductive |  43.2 ± 0.3 | 60.2 ± 0.3 | [\[PyTorch\]](https://gitlab.mpi-klsb.mpg.de/yaoyaoliu/e3bm) | [\[Source\]](https://arxiv.org/pdf/1904.08479.pdf)
[E<sup>3</sup>BM](https://arxiv.org/pdf/1904.08479.pdf) | ECCV | 2020 | WRN-28-10 | Transductive |  46.0 ± 0.6 | 57.1 ± 0.4 | [\[PyTorch\]](https://gitlab.mpi-klsb.mpg.de/yaoyaoliu/e3bm) | [\[Source\]](https://arxiv.org/pdf/1904.08479.pdf)
[J. Kim et al.](http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123460579.pdf) | ECCV | 2020 |  ResNet-12 | Inductive |  42.31 ± 0.75 | 58.16 ± 0.78 | [\[PyTorch\]](https://github.com/jaekyeom/MABAS) | [\[Source\]](http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123460579.pdf)
[Centroid](http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123500018.pdf) | ECCV | 2020 |  ResNet-18 | Inductive |  45.83 ± 0.48 | 59.74 ± 0.56 | [\[PyTorch\]](https://github.com/ArmanAfrasiyabi/associative-alignment-fs) | [\[Source\]](http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123500018.pdf)
[Y. Tian et al.](http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123590256.pdf) | ECCV | 2020 | ResNet-12 | Inductive | 44.6 ± 0.7 | 60.9 ± 0.6 | [\[PyTorch\]](https://github.com/WangYueFt/rfs) | [\[Source\]](http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123590256.pdf)
[F. Wu et al.](http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123730239.pdf) | ECCV | 2020 | Capsule Network | Inductive | 47.5 ± 0.9  | 59.8 ± 1.0 | None | [\[Source\]](http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123730239.pdf)
[ConstellationNet](https://openreview.net/pdf?id=vujTf_I8Kmc)     | ICLR   | 2021 | ResNet-12   | Inductive | 43.8 ± 0.2    | 59.7 ± 0.2     | None | [\[Source\]](https://openreview.net/pdf?id=vujTf_I8Kmc)
[Rizve et al.](https://openaccess.thecvf.com/content/CVPR2021/papers/Rizve_Exploring_Complementary_Strengths_of_Invariant_and_Equivariant_Representations_for_Few-Shot_CVPR_2021_paper.pdf) | CVPR | 2021 | ResNet-12 | Inductive | 47.76±0.77 | 65.30±0.76 | None | [\[Source\]](https://openaccess.thecvf.com/content/CVPR2021/papers/Rizve_Exploring_Complementary_Strengths_of_Invariant_and_Equivariant_Representations_for_Few-Shot_CVPR_2021_paper.pdf)
[PLCM](https://openaccess.thecvf.com/content/ICCV2021/papers/Huang_Pseudo-Loss_Confidence_Metric_for_Semi-Supervised_Few-Shot_Learning_ICCV_2021_paper.pdf) | ICCV | 2021 | ResNet-12 | Semi-supervised | 48.35±1.00 | 62.75±0.82 | None | [\[Source\]](https://openaccess.thecvf.com/content/ICCV2021/papers/Huang_Pseudo-Loss_Confidence_Metric_for_Semi-Supervised_Few-Shot_Learning_ICCV_2021_paper.pdf)
[TPMN](https://openaccess.thecvf.com/content/ICCV2021/papers/Wu_Task-Aware_Part_Mining_Network_for_Few-Shot_Learning_ICCV_2021_paper.pdf) | ICCV | 2021 | ResNet-12 | Inductive | 46.93±0.71 | 63.26±0.74 | None | [\[Source\]](https://openaccess.thecvf.com/content/ICCV2021/papers/Wu_Task-Aware_Part_Mining_Network_for_Few-Shot_Learning_ICCV_2021_paper.pdf)
[Meta Navigator](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_Meta_Navigator_Search_for_a_Good_Adaptation_Policy_for_Few-Shot_ICCV_2021_paper.pdf) | ICCV | 2021 | ResNet-12 | Inductive | 46.40±0.81 | 61.33±0.71 |  None  | [\[Source\]](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_Meta_Navigator_Search_for_a_Good_Adaptation_Policy_for_Few-Shot_ICCV_2021_paper.pdf)
[MixtFSL](https://openaccess.thecvf.com/content/ICCV2021/papers/Afrasiyabi_Mixture-Based_Feature_Space_Learning_for_Few-Shot_Image_Classification_ICCV_2021_paper.pdf) | ICCV | 2021 | ResNet-12 | Inductive | 44.89±0.63 | 60.70±0.6 |  [\[PyTorch\]](https://github.com/ArmanAfrasiyabi/MixtFSL-fs)| [\[Source\]](https://openaccess.thecvf.com/content/ICCV2021/papers/Afrasiyabi_Mixture-Based_Feature_Space_Learning_for_Few-Shot_Image_Classification_ICCV_2021_paper.pdf)
